\chapter{The Histogram of Gradient Orientations of Signal Plots}
\label{chapter:three}

This Chapter introduces the EEG feature extraction procedure based on the Histogram of Gradient Orientations.  This method is grounded on an extension and modification of the SIFT~\cite{Lowe2004} Descriptor which is used in Computer Vision to extract and map local regions of an image.  At the same time, this Chapter brings to completion the previous one, describing how to mine the information from the Plot and build a feature out of it.

\section{Introduction}

%sinuplot, spectrogram, scalogram

The work of Edelman, Intrator and Poggio~\cite{cogprints561} on how the visual cortex sense features was the inspiration to the development of an algorithm to identify and decode salient local information from image regions.  The Scale Invariant Feature Transform (SIFT) method is composed of two parts, the SIFT Detector and the SIFT Descriptor.  The first is the procedure to identify relevant areas of an image.  The second is the procedure to describe and characterize a region of an image using the Histogram of Gradient Orientations~\footnote{It should not to be confused with HOG~\cite{Dalal2005}, the Histogram Of Gradients which is another method from Computer Vision based on similar ideas.  Actually, the descriptor part of the SIFT Method has no specific name, but as it is based on building a histogram of gradient orientations, that is the reason why it is described here in that way. }.  The SIFT algorithm is biomimetically inspired in how the visual cortex detects shapes by analyzing orientations~\cite{cogprints561}.  The patch description is also based on the Theory of Receptive Fields and other related ideas~\cite{Lindeberg2013}.

\section{Feature Extraction: Histogram of Gradient Orientations}
\label{SIFT}

The basic procedure is composed of,

\begin{enumerate}
\item Keypoints $\gls{kp}$ are located on an image of a signal plot.
\item A region of an image, a patch, is located using keypoints as centers.  Each patch has a horizontal $\gls{St}$ and vertical scale $\gls{Sv}$, which determines a size in pixels along the horizontal $\gls{Sx}$ and vertical $\gls{Sy}$ axis. 
\item Form each patch, a descriptor $\mathbf{d}$ is derived which is used as a representation of the graphical information contained within the patch.
\end{enumerate}

On the image generated by the procedure detailed in previous Chapter, a keypoint $\gls{kp}$ is placed on a pixel $(x_{kp}, y_{kp})$ over the image plot and a window around the keypoint is considered. A local image patch of size $\gls{Sx} \times \gls{Sy}$ pixels is constructed by dividing the window in $16$ blocks. It is arranged in a $4 \times 4$ grid and the pixel $\gls{kp}$ is the patch center. 

A local representation of the signal shape within the patch can be described by obtaining the gradient orientations on each of the $16$ blocks and creating a histogram of gradients.  This technique is the basis of Lowe's SIFT Descriptor method. In order to calculate the histogram, the interval $[0-360]$ of possible angles is divided in $8$ bins, each one at $45$ degrees.

 Hence, for each spacial bin $ i,j = \{0,1,2,3\} $, corresponding to the indexes of each block $B_{i,j}$,  the orientations are accumulated in a  $3$-dimensional histogram $h$ through the following equation: 
 

\begin{equation}
 h(\theta,i,j) = \sum_{\mathbf{p}} w_\mathrm{ang}(\angle J(\mathbf{p}) - \theta)\, w_{ij}\left(\mathbf{p} - \mathbf{kp} \right)\, |J(\mathbf{p})|
\label{eq:histogram}
\end{equation}

\noindent  where $\mathbf{p}$ is a pixel from within the patch,  $\theta$ is the angle bin with $ \theta \in \{0, 45, 90, 135, 180, 225, 270, 315\} $,  $ |J(\mathbf{p})| $ is the norm of the gradient vector in the pixel $\mathbf{p}$ and it is computed using finite differences and $\angle J(\mathbf{p}) $ is the angle of the gradient vector.  The scalar $ w_\mathrm{ang}(\cdot) $  and vector $ w_{ij}(\cdot) $ functions are linear interpolations used by~\cite{Lowe2004} and \cite{Vedaldi2010} to provide a weighting contribution to eight adjacent bins.  They are calculated as  

\begin{equation}
 w_{ij}(\mathbf{v}) = w( \frac{v_x - x_i}{3 \; \gls{Sx}} ) w( \frac{v_y - y_i}{3 \; \gls{Sy}} ) 
\label{eq:ij}
\end{equation}

\begin{equation}
 w_\mathrm{ang}(\alpha) = \sum_{k} w( \frac{8\alpha}{2\pi} + 8r)
\label{eq:wang}
\end{equation}

\noindent where $x_i$ and $y_i$ are the spatial bin centers located in $ x_i,y_i = \{-\frac{3}{2},-\frac{1}{2},\frac{1}{2},\frac{3}{2}\} $. The function parameter $\mathbf{v} = ( v_x, v_y ) $ is a vector variable and $\alpha$ a scalar variable.  On the other hand, $r$ is an integer that can vary freely which allows the argument $\alpha$ to be unconstrained in terms of its values in radians. The interpolating function $w(\cdot)$ is defined as:

\begin{equation}
 w(z) = \max(0,|z|-1).
\label{eq:weighting}
\end{equation}

These binning functions conform a trilinear interpolation that has a combined effect of sharing the contribution of each oriented gradient between their eight adjacent bins in a tridimensional cube in the histogram space, and zero everywhere else.

Lastly, the fixed value of $ 3 $ on Equation~\ref{eq:ij} is a magnification factor, a fixed parameter.  As the patch has  $16$ blocks and  $8$ bin angles are considered, a feature called \textit{descriptor} of $128$ dimension is obtained. 
%It can be observed that the histogram is computed by multiplying by $ |J(\mathbf{p})| $, so the method considers both, the magnitude and the orientation of the gradient vector. 

Figure~\ref{fig:sampledescriptor} shows an example of a patch and a scheme of the histogram computation. In (A) a plot of the signal and the patch centered around the keypoint is shown. In (B) the possible orientations on each patch are illustrated.  Only the upper-left four blocks are visible.  The first eight orientations of the first block, are labeled from $1$ to $8$ clockwise. The orientations of the second block $ B_{1,2} $ are labeled from $9$ to $16$.  This labeling continues left-to-right, up-down until the eight orientations for all the sixteen blocks are assigned. They form the corresponding $\mathbf{kp}$-descriptor of $128$ coordinates. Finally, in (C) an enlarged image plot is shown where the oriented gradient vector for each pixel can be seen.

\begin{figure}[h!]
\centering
\includegraphics[width=16cm]{images/gradients.png}\label{samplegradients}
\caption[Histogram of Gradient Orientations for ERP]{ (A) Example of a plot of the signal, a keypoint and the corresponding patch. (B) A scheme of the orientation's histogram computation.  Only the upper-left four blocks are visible.  The first eight orientations of the first block, are labeled from $1$ to $8$ clockwise. The orientation of the second block $ B_{1,2} $ is labeled from $9$ to $16$.  This labeling continues left-to-right, up-down until the eight orientations for all the sixteen blocks are assigned. They form the corresponding descriptor of $128$ coordinates.  The length of each arrow represent the value of the histogram on each direction for each block. (C) Vector field of oriented gradients.  Each pixel is assigned an orientation and magnitude calculated  using finite differences. }
\label{fig:sampledescriptor}
\end{figure}

%\begin{figure}[h!]
%\centering
%\includegraphics[scale=0.6]{images/KeypointLocations.eps}
%\caption[SIFT Patches]{fdsfdfsfs }
%\label{fig:siftpatch}
%\end{figure}


\section{Keypoint Location}

%TODO Vertidal: Along the signal or zero level.
% Horizontal: based on a cognitive event, one or many.
%


The keypoint $\gls{kp}$ location must be accurate specified in order to establish the region from the signal where the waveform is located.

For the horizontal position, the localization of the keypoint is based on a priori information, based on the characteristics of the event under study.  For instance, ERPs have a specific timing that can be explored to elucidate in which position the expected signal pattern will be generated.

But the main answer to respond is how many descriptors are needed, and this also leads to density of descriptors.  How many per pixel or per sample point.

Additionally, there can be more than just one patch located over the signal plot.  This is particular important for oscillatory processes and defines a descriptor density parameter $s_d$.

\begin{figure}[h!]
\centering
\subfigure[Fixed size descriptors are located are alogn the EEG signal trace at a given descriptor density $s_d$.]
{\includegraphics[width=6cm, height=6cm]{images/SignalWithFullDescriptors3.png}}
\subfigure[A descriptor is used to map an artificial signal using an autoscale plotting scheme, and mapping the entire waveform within the patch.]
{\includegraphics[width=6cm, height=6cm]{images/EasyDescriptorSample3.png}}
\subfigure[Only one fixed size descriptor is used on a very specific position of the signal.]
{\includegraphics[width=6cm, height=6cm]{images/SignalWithDescriptorSample1.png}}
\subfigure[An entire signal is mapped with fixed size descriptors with a very high descriptor density $s_d$.]
{\includegraphics[width=6cm, height=6cm]{images/SignalWithFullDescriptors2.png}}
\caption[Keypoint Locations]{Four different alternatives of keypoint locations and patch geometry.}.
\label{fig:keypointlocations}
\end{figure}

Regarding the Vertical Location, there are two options.  The first one is along the signal, exactly on the sample points calculated by the Equation \ref{eq:images}.  The second is on a fixed position over the zero-level as described by \ref{eq:zerolevel}.

\section{Patch Geometry}

%TODO Vertical size: Fixed for autoscaled and variable.
% Horizontal: based on a priori information


The Horizontal Patch Scale $\gls{St}$ determines the size of the patch on the image horizontal axis, and it is related to the span $\gls{lambda}$ of the waveform to analyze according to

\begin{equation}
\gls{St} = \frac{ \gls{lambda} \;  \  \gls{Fs} \ \gls{gammat} }{\gls{Deltas}}
\label{eq:horizontalpatchscale}
\end{equation}

\noindent where $\gls{Fs}$ is the sample frequency, $\gls{gammat}$ is the time scale factor and $\gls{Deltas}$ is the pixel conversion factor.

On the other hand, on the vertical axis, the vertical patch scale depends on the peak-to-peak amplitude $\gls{DeltamuV}$.

\begin{equation}
\gls{Sv} = \frac{\gls{St} \ \gls{gamma}}{\gls{Deltas}} 
\label{eq:mapping1}
\end{equation}

The vertical scale can be dynamically adjusted according to the peak-to-peak amplitude of each segment, or it can be set fixed.  This is more appropiate if the underlying signal is bounded which is the case if the standardized procedure described in \ref{standardized} is applied.

Figure~\ref{fig:patchgeometry} shows the different parameters of the patch.

\begin{figure}[h!]
\centering
\includegraphics[width=10cm]{images/patchgeometry.pdf}
\caption[Patch Geometry]{The scale of local patch is selected in order to capture the whole transient event.  The size of the patch is $\gls{Sy} \times \gls{Sx}$ pixels. The vertical size consists of $4$ blocks of size $\gls{Sy}$ pixels which should be high enough as to contain the signal $\gls{DeltamuV}$, the peak-to-peak amplitude of the signal component. The horizontal size includes $4$ blocks up to $\gls{Sx}$ and should covert the entire duration in seconds of the signal waveform, $ \gls{lambda} $.   }
\label{fig:patchgeometry}
\end{figure}

Once this parameters are set, the size in pixels of the patch can be obtained in both dimensions.  The Horizontal Patch Size in pixels is

\begin{equation}
\gls{Sx} = \gls{Deltas} \; \gls{St} + 1.
\label{eq:sx}
\end{equation}

The Vertical Patch Size in pixels can be calculated from

\begin{equation}
\gls{Sy} = \gls{Deltas} \; \gls{Sv} + 1
\label{eq:sy}
\end{equation}

\noindent where $\gls{Deltas}$ is a fixed parameter value which depends on the SIFT implementation. The parameters $\gls{St}$  and $\gls{Sv}$ are the scales of the local patch. This region is arranged in a $4 \times 4$ grid and the pixel $\gls{kp}$ is the patch center. 

The patch size cannot be bigger than the image, whose width is $\gls{Wx}$ and height is $\gls{Hy}$ .  This is reflected by the following two inequalities that restrict the size of the patch according to 

\begin{equation}
\frac{\gls{Wx}-1}{\gls{Deltas}}  \geq \gls{St} 
\label{eq:restriction1}
\end{equation}

\noindent on the horizontal axis, and on the vertical axis, 

\begin{equation}
\frac{\gls{Hy}-1}{\gls{Deltas}}  \geq \gls{Sv}.
\label{eq:restriction2}
\end{equation}

\subsection{Oscillatory Processes}

For these patterns, the central idea is to locate keypoints, and their patches all along the signal trace and filling the entire signal segments with all the possible patches.  In this case, the descriptor density determines the step at which a keypoint is located along the trace of the signal, pixel after pixel.  Close to the margins, there is a gap to avoid locating incomplete patches.  This can be observed in Figure~\ref{fig:keypointlocations}(a).

\subsection{Transient Events}

For transient events, descriptors are treated as representatives of the signals itself so there is just one descriptor that is located in a meaningfull position along the time axis.

Additionally, for autoscale plotting, the zero level can be used to localize keypoints.

\section{Classification}
\label{nbnn}

A discriminative~\cite{WolpawJonathanR2012} semi-supervised classification method based on Naive Bayes Nearest Neighbor~\cite{Boiman2008} was applied to classify EEG signals using the features provided by the calculated descriptors.
One problem that frequently arises when using local features is how to go back from the classification of those local characteristics to the image where those descriptors came from.
The NBNN technique overcomes this problem by comparing each image against a whole label class which is characterized by the set of descriptors that are closest to each one of the descriptors of the query image. This algorithm is very easy to implement, and is based on the following Equation:

\begin{equation}
\hat{L} = \arg \min_{L} \sum_{\mathbf{d_i}^{(c)}} \sum_{q \in N_T(\mathbf{d_i}^{(c)})}^{} {\left\lVert q -  \mathbf{d_i}^{(c)} \right\rVert}  ^{2} .
\label{eq:classification}
\end{equation}

The estimated class $\hat{C}$ of a query image is calculated as the class $C$ that minimize the summation of the distance between each descriptor $\mathbf{d_i}^{(c)}$ that belongs to the query image and its corresponding near neighbot $N_T(\mathbf{d}^{(bpc)})$  descriptor for each class.


\begin{figure}[h!]
\centering
\subfigure[]
{\includegraphics[scale=0.25]{images/NBNNMethod1.png}}
\subfigure[]
{\includegraphics[scale=0.25]{images/NBNNMethod2.png}}
\subfigure[]
{\includegraphics[scale=0.25]{images/NBNNMethod3.png}}
\subfigure[]
{\includegraphics[scale=0.25]{images/NBNNMethod4.png}}
\subfigure[ ]
{\includegraphics[scale=0.25]{images/NBNNMethod5.png}}
\caption[NBNN Classification]{(a) Two Dictionaries contain templates descriptors for two different classes. A set of query descriptors are extracted from a new image that needs to be categorized.(b) Distances from every descriptor $di$ is calculated against the closest one from the Dictionary of Class 2.  Distances are accumulated.(c) Distances from every descriptor $di$ is calculated against the closest one from the Dictionary of Class 1.  Distances are accumulated. (d) The two different values are compared.(e) The summation that achieved the lesser value is the one that more closely resemble the set of templates, thus is the one predicted by the classification algorithm.}
\label{fig:nbnnclassification}
\end{figure}

%TODO:Agregar tambien las pruebas sobre rootsift y que la distancia mejor es la coseno demostrar justamente haciendo una prueba sobre EEGWave.
%TODO:Agregar que el experimento dio perfecto cuando no se controla la varianza.

\section{BCI Algorithm}

In brief, based on segmented signals from at least two labeled classes, a set of images is first generated.  For each image, desctipros are extracted during the training or calibration step of a BCI procedure and they are grouped in KD-tree~\cite{Lowe2004} structures for each one of the classes.

Hence, given a new unlabeled signal segment, an image plot is generated as well, and their descriptors extracted.  They are fed into Equation~\ref{eq:classification} in order to determine the class which minimizes the summation and thus provide the information bit to the BCI controller.  

\section{Implementation}

\subsection{Software}

The implemented code is published in \url{https://bitbucket.org/itba/hist/} by using Matlab, python and the VLFeat library.

%TODO add the data and also the code ocean repository.  Also add my own repositories.

\section{Implementation Summary}

This section provides a mapping cheat sheet to convert and obtain the parameters of the algorithm for a given set of signal parameters.

The input signal parameters are $N$,$F_s$ and $\lambda$. The peak-to-peak amplitude of the waveform to study is $ \Delta \mu V $. The unit length of the patch is $\Delta_s = \sqrt{2} \; 15$.  

Output parameters are: 
$\gls{N}$, 
$\gls{lambda}$
$\gls{Fs}$
$\gls{Deltas}$
$\gls{DeltamuV}$
$\gls{gamma}$
$\gls{gammat}$
$\gls{Hy}$
$\gls{Wx}$
$\gls{St}$
$\gls{Sv}$
$\gls{Sy}$
$\gls{Sx}$
$\gls{w}$
$\gls{kp}$
$\gls{P}$

Amplitude scale factor

\begin{equation}
\gamma \equiv \frac{H_y}{\Delta \mu V}  
\label{eq:gammadefinition}
\end{equation}

Time scale factor

\begin{equation}
\gamma_t \equiv \frac{W_x}{F_s \; w}  
\label{eq:gammatdefinition}
\end{equation}

%\begin{equation}
%s_x = \frac{ \gamma \;  \lambda \  F_s}{12}
%\label{eq:mapping2}
%\end{equation}
%
%\begin{equation}
%s_y= \frac{\gamma \; \Delta \mu V}{12} 
%\label{eq:mapping1}
%\end{equation}

Restriction on the waveform time scale

\begin{equation}
\frac{W_x-1}{\sqrt{2} \; 15}  \geq S_t 
\label{eq:restriction1}
\end{equation}

Restriction on the waveform amplitude scale

\begin{equation}
\frac{H_y-1}{\sqrt{2} \; 15}  \geq S_v 
\label{eq:restriction2}
\end{equation}

Horizontal Patch scale

\begin{equation}
S_t = \frac{ \lambda \;  \  F_s \ \gamma_t }{\Delta_s}
\label{eq:mapping2}
\end{equation}

Vertical Patch scale

\begin{equation}
S_v= \frac{\Delta \mu V \ \gamma}{\Delta_s} 
\label{eq:mapping1}
\end{equation}

Time to sample point conversion

\begin{equation}
n = \left\lfloor F_s \ \Delta_t \right\rfloor \ \gamma_t
\label{eq:mapping1}
\end{equation}

Horizontal Patch size in pixels

\begin{equation}
\mathbf{S}_x = \Delta_s \; S_t + 1
\label{eq:mapping2}
\end{equation}

Vertical Patch Size in pixels

\begin{equation}
\mathbf{S}_y = \Delta_s \; S_v + 1
\label{eq:mapping1}
\end{equation}

Span of a Patch

\begin{equation}
\Delta_t = \frac{S_t \ \Delta_s}{F_s \ \gamma_t} 
\label{eq:mapping1}
\end{equation}
